{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "tf.debugging.set_log_device_placement(False)\n",
    "\n",
    "os.environ[\"TFHUB_DOWNLOAD_PROGRESS\"] = \"True\"\n",
    "\n",
    "dry_run = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "print(tf.test.is_built_with_cuda()) \n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(image, filename):\n",
    "    \"\"\"\n",
    "    Saves unscaled Tensor Images.\n",
    "    Args:\n",
    "      image: 3D image tensor. [height, width, channels]\n",
    "      filename: Name of the file to save to.\n",
    "    \"\"\"\n",
    "    if not isinstance(image, Image.Image):\n",
    "        image = tf.clip_by_value(image, 0, 255)\n",
    "        image = Image.fromarray(tf.cast(image, tf.uint8).numpy())\n",
    "    image.save(f'{filename}.jpg')\n",
    "    print(f'Saved as {filename}.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_multiple_images, plot_single_image\n",
    "\n",
    "\n",
    "plot_multiple_images(tf.random.normal((2, 16, 32, 32, 3)) * 255, 'Gaussian noise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from esrgan import ESRGAN\n",
    "from os import path\n",
    "from data import CLEAR_IMAGES_DIR, get_dataset\n",
    "\n",
    "\n",
    "# ds_iter = \n",
    "\n",
    "# model = ESRGAN()\n",
    "# model.load()\n",
    "\n",
    "# for i in range(3):\n",
    "X, y = next(iter(get_dataset(path.join(CLEAR_IMAGES_DIR, 'train')).batch(1)))\n",
    "#     enhanced_batch = model(X)\n",
    "# plot_multiple_images([tf.expand_dims(X[0], axis=0), tf.expand_dims(X[1], axis=0)], 'Enhanced vs groud truth HR images', cmap='gray', figsize=(6, 6))\n",
    "plot_single_image(X[0], 'LR image (128, 128)')\n",
    "plt.figure()\n",
    "plot_single_image(y[0], 'HR image (256, 256)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LeakyReLU, Dropout, Flatten, Conv2D, Dense\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "\n",
    "class Discriminator(Model):\n",
    "    def __init__(self, input_shape):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=input_shape)\n",
    "        self.lrelu1 = LeakyReLU()\n",
    "        self.dropout1 = Dropout(0.3)\n",
    "        \n",
    "        self.conv2 = Conv2D(128, (5, 5), strides=(2, 2), padding='same')\n",
    "        self.lrelu2 = LeakyReLU()\n",
    "        self.dropout2 = Dropout(0.3)\n",
    "        \n",
    "        self.conv3 = Conv2D(64, (3, 3), strides=(2, 2), padding='same')\n",
    "        self.lrelu3 = LeakyReLU()\n",
    "        \n",
    "        self.conv4 = Conv2D(32, (3, 3), strides=(2, 2), padding='same')\n",
    "        self.lrelu4 = LeakyReLU()\n",
    "        \n",
    "        self.flatten = Flatten()\n",
    "        self.dense = Dense(1, activation=None)\n",
    "    \n",
    "    def __call__(self, X, training=True):\n",
    "        outputs = self.conv1(X)\n",
    "        outputs = self.lrelu1(outputs)\n",
    "        outputs = self.dropout1(outputs, training=training)\n",
    "        \n",
    "        outputs = self.conv2(outputs)\n",
    "        outputs = self.lrelu2(outputs)\n",
    "        outputs = self.dropout2(outputs, training=training)\n",
    "\n",
    "        outputs = self.conv3(outputs)\n",
    "        outputs = self.lrelu3(outputs)\n",
    "        \n",
    "        outputs = self.conv4(outputs)\n",
    "        outputs = self.lrelu4(outputs)\n",
    "        \n",
    "#         print(outputs.shape)\n",
    "\n",
    "        return self.dense(self.flatten(outputs))\n",
    "    \n",
    "    \n",
    "    def call(self, inputs, training=True):\n",
    "        return self(inputs, training=training)\n",
    "\n",
    "    \n",
    "def test_discriminator():\n",
    "    batch_size = 8\n",
    "    inp_shape = batch_size, 256, 256, 3\n",
    "    d = Discriminator(input_shape=inp_shape)\n",
    "\n",
    "    assert d(tf.ones(inp_shape)).shape == (batch_size, 1)\n",
    "    print('Correct discriminator outputs.')\n",
    "    \n",
    "\n",
    "test_discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TunedESRGAN(Model):\n",
    "    def __init__(self, input_shape, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        self.base_model = hub.KerasLayer('https://tfhub.dev/captain-pool/esrgan-tf2/1', input_shape=input_shape, trainable=True)\n",
    "        \n",
    "    def __call__(self, X, training=True):\n",
    "        return self.base_model(X, training=training)\n",
    "    \n",
    "    def call(self, inputs, training=True):\n",
    "        return self(inputs, training=training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from core.pan import PixelAttentionSRNetwork\n",
    "from itertools import cycle\n",
    "\n",
    "    \n",
    "# # b = SCPA(3)\n",
    "# # b(tf.ones((8, 64, 64, 3))).shape\n",
    "batch_size = 32\n",
    "inp_shape = (batch_size, 64, 64, 3)\n",
    "# net = PixelAttentionSRNetwork(feat_extr_n_filters=30, upsamp_n_filters=20, n_blocks=16, scale=4, input_shape=inp_shape)\n",
    "# net.build(inp_shape)\n",
    "# # print(net(tf.ones(inp_shape)).shape)\n",
    "# net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gan = TunedESRGAN(inp_shape)\n",
    "# gan.build(inp_shape)\n",
    "# gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "\n",
    "# t = time.time()\n",
    "# gan(tf.ones(inp_shape))\n",
    "\n",
    "# print('Single forward step for ESRGAN took', time.time() - t) # 16.393023014068604"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = time.time()\n",
    "# net(tf.ones(inp_shape))\n",
    "\n",
    "# print('Single forward step for PAN took', time.time() - t) # 3.076345920562744"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy_loss = tf.keras.losses.BinaryCrossentropy()\n",
    "sigmoid = tf.keras.activations.sigmoid\n",
    "\n",
    "\n",
    "# def discriminator_loss(real_outputs, fake_outputs):\n",
    "#     return (cross_entropy_loss(tf.zeros_like(fake_outputs), fake_outputs) + \n",
    "#             cross_entropy_loss(tf.ones_like(real_outputs), real_outputs))\n",
    "\n",
    "\n",
    "# def generator_loss(fake_outputs):\n",
    "#     return cross_entropy_loss(tf.ones_like(fake_outputs), fake_outputs)\n",
    "\n",
    "\n",
    "def discriminator_loss(real_outputs, fake_outputs):\n",
    "    \"\"\"Relativistic discriminator loss\"\"\"\n",
    "    # both real_outputs and fake_outputs are logits(non-transformed discriminator output)\n",
    "    # real data is more realistic than fake data \n",
    "    real_realistics_coeff = sigmoid(real_outputs - tf.reduce_mean(fake_outputs))\n",
    "    # fake data is less realistic than real data \n",
    "    fake_realistics_coeff = sigmoid(fake_outputs - tf.reduce_mean(real_outputs))\n",
    "    \n",
    "    return (cross_entropy_loss(tf.zeros_like(fake_outputs), real_realistics_coeff) + \n",
    "            cross_entropy_loss(tf.ones_like(real_outputs), fake_realistics_coeff))\n",
    "\n",
    "\n",
    "def generator_loss(real_outputs, fake_outputs):\n",
    "    \"\"\"Relativistic generator loss\"\"\"\n",
    "    # real data is more realistic than fake data \n",
    "    real_realistics_coeff = sigmoid(real_outputs - tf.reduce_mean(fake_outputs))\n",
    "    # fake data is less realistic than real data \n",
    "    fake_realistics_coeff = sigmoid(fake_outputs - tf.reduce_mean(real_outputs))\n",
    "    \n",
    "    return (cross_entropy_loss(tf.ones_like(fake_outputs), real_realistics_coeff) + \n",
    "            cross_entropy_loss(tf.zeros_like(real_outputs), fake_realistics_coeff))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "from data import CLEAR_IMAGES_DIR, LR_IMAGE_SIZE, HR_IMAGE_SIZE\n",
    "from utils import plot_multiple_images, plot_single_image\n",
    "from core.pan import PixelAttentionSRNetwork\n",
    "from itertools import cycle\n",
    "\n",
    "\n",
    "input_lr_shape = (None, *LR_IMAGE_SIZE, 3)\n",
    "input_hr_shape = (None, *HR_IMAGE_SIZE, 3)\n",
    "\n",
    "cpu = '/CPU:0'\n",
    "# gpu = '/GPU:0'\n",
    "\n",
    "device = cpu\n",
    "\n",
    "max_ckpt_to_keep = 3\n",
    "checkpoint_dir = './model/x2_checkpoints'\n",
    "checkpoint_name = 'pix-att-net-ckpt'\n",
    "\n",
    "\n",
    "with tf.device(device):\n",
    "    test_dataset = cycle(get_dataset(path.join(CLEAR_IMAGES_DIR, 'train')).batch(4))\n",
    "    \n",
    "    sr_net = PixelAttentionSRNetwork(input_lr_shape, feat_extr_n_filters=30, upsamp_n_filters=20, n_blocks=16, scale=2)\n",
    "    \n",
    "    checkpoint = tf.train.Checkpoint(sr_net=sr_net)\n",
    "\n",
    "    sr_net.build(input_lr_shape)\n",
    "\n",
    "    ckpt_manager = tf.train.CheckpointManager(checkpoint, checkpoint_dir, max_ckpt_to_keep, checkpoint_name=checkpoint_name)\n",
    "\n",
    "    # try restoring previous checkpoint or initialize a new one\n",
    "    restored_ckpt_path = ckpt_manager.restore_or_initialize()\n",
    "    if restored_ckpt_path:\n",
    "        print('Restored state from checkpoint {}'.format(repr(restored_ckpt_path)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(test_dataset)\n",
    "plot_multiple_images([X, np.ones(X.shape) * 255], figsize=(6, 6), title=f'Source images')\n",
    "\n",
    "print('Max possible psnr', round(float(tf.reduce_mean(tf.image.psnr(y, y, 255))), 4))\n",
    "\n",
    "y_hat = tf.image.resize(X, HR_IMAGE_SIZE, method='bilinear')\n",
    "psnr = round(float(tf.reduce_mean(tf.image.psnr(y, y_hat, 255))), 4)\n",
    "plot_multiple_images([y_hat, y], figsize=(6, 6), title=f'Bilinear inter PSNR: {psnr}')\n",
    "# plot_multiple_images([y_hat, y], figsize=(6, 6))\n",
    "# plt.savefig('./x4/bilinear_inter_results.png')\n",
    "\n",
    "\n",
    "y_hat = tf.image.resize(X, HR_IMAGE_SIZE, method='bicubic')\n",
    "psnr = round(float(tf.reduce_mean(tf.image.psnr(y, y_hat, 255))), 4)\n",
    "plot_multiple_images([y_hat, y], figsize=(6, 6), title=f'Bicubic inter PSNR: {psnr}')\n",
    "# plot_multiple_images([y_hat, y], figsize=(6, 6))\n",
    "# plt.savefig('./x4/bicubic_inter_results.png')\n",
    "\n",
    "y_hat = tf.clip_by_value(sr_net(X, training=False), 0, 255)\n",
    "psnr = round(float(tf.reduce_mean(tf.image.psnr(y, y_hat, 255))), 4)\n",
    "msssim = round(float(tf.reduce_mean(tf.image.ssim_multiscale(y_hat, y, 255))), 4)\n",
    "# print(msssim)\n",
    "plot_multiple_images([y_hat, y], figsize=(6, 6), title=f'Model PSNR: {psnr}. MS-SSIM: {msssim}')\n",
    "# plot_multiple_images([y_hat, y], figsize=(6, 6))\n",
    "# plt.savefig('./x4/sr_model_inter_results.png')\n",
    "\n",
    "# model = ESRGAN()\n",
    "# model.load()\n",
    "\n",
    "# y_hat = tf.clip_by_value(model(X), 0, 255)\n",
    "# psnr = round(float(tf.reduce_mean(tf.image.psnr(y, y_hat, 255))), 4)\n",
    "# plot_multiple_images([y_hat, y], figsize=(6, 6), title=f'Bilinear inter PSNR: {psnr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# psnr_test_model = gen\n",
    "from functools import partial\n",
    "\n",
    "# partial()\n",
    "\n",
    "# psnr_test_model = partial(tf.image.resize, size=HR_IMAGE_SIZE, method='bilinear')\n",
    "# psnr_test_model = partial(tf.image.resize, size=HR_IMAGE_SIZE, method='bicubic')\n",
    "psnr_test_model = partial(sr_net, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_batch_psnr = 0.0\n",
    "mean_batch_ssim = 0.0\n",
    "mean_batch_msssim = 0.0\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    batch_size = 50\n",
    "    dataset = get_dataset(path.join(CLEAR_IMAGES_DIR, 'test'))\n",
    "    n_batches = 0\n",
    "    for batch_x, batch_y in dataset.batch(batch_size):\n",
    "        y_hat = psnr_test_model(batch_x)\n",
    "        mean_batch_psnr += tf.reduce_mean(tf.image.psnr(y_hat, batch_y, 255))\n",
    "        mean_batch_ssim += tf.reduce_mean(tf.image.ssim(y_hat, batch_y, 255))\n",
    "        mean_batch_msssim += tf.reduce_mean(tf.image.ssim_multiscale(y_hat, batch_y, 255))\n",
    "        n_batches += 1\n",
    "\n",
    "mean_batch_psnr /= n_batches\n",
    "mean_batch_ssim /= n_batches\n",
    "mean_batch_msssim /= n_batches\n",
    "print('PSNR:', round(float(mean_batch_psnr), 4))\n",
    "print('SSIM:', round(float(mean_batch_ssim), 4))\n",
    "print('MSSSIM:', round(float(mean_batch_msssim), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
