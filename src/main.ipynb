{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "tf.debugging.set_log_device_placement(False)\n",
    "\n",
    "os.environ[\"TFHUB_DOWNLOAD_PROGRESS\"] = \"True\"\n",
    "\n",
    "dry_run = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "print(tf.test.is_built_with_cuda()) \n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_multiple_images, plot_single_image\n",
    "\n",
    "\n",
    "plot_multiple_images(tf.random.normal((2, 16, 32, 32, 3)) * 255, 'Gaussian noise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "from data import CLEAR_IMAGES_DIR, get_dataset\n",
    "\n",
    "X, y = next(iter(get_dataset(path.join(CLEAR_IMAGES_DIR, 'train')).batch(1)))\n",
    "# plot_multiple_images([tf.expand_dims(X[0], axis=0), tf.expand_dims(X[1], axis=0)], 'Enhanced vs groud truth HR images', cmap='gray', figsize=(6, 6))\n",
    "plot_single_image(X[0], 'LR image')\n",
    "plt.figure()\n",
    "plot_single_image(y[0], 'HR image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.esrgan import ESRGAN\n",
    "\n",
    "\n",
    "esrgan = ESRGAN()\n",
    "esrgan.load()\n",
    "\n",
    "enhanced_batch = esrgan(X)\n",
    "\n",
    "plot_single_image(enhanced_batch[0], 'ESRGAN enhanced image', cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = time.time()\n",
    "# net(tf.ones(inp_shape))\n",
    "\n",
    "# print('Single forward step for PAN took', time.time() - t) # 3.076345920562744"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "from data import CLEAR_IMAGES_DIR, LR_IMAGE_SIZE, HR_IMAGE_SIZE\n",
    "from utils import plot_multiple_images, plot_single_image\n",
    "from src.models.pan import PAN\n",
    "from itertools import cycle\n",
    "\n",
    "\n",
    "input_lr_shape = (None, 128, 128, 3)\n",
    "input_hr_shape = (None, 256, 256, 3)\n",
    "scale = 2\n",
    "\n",
    "cpu = '/CPU:0'\n",
    "# gpu = '/GPU:0'\n",
    "\n",
    "device = cpu\n",
    "\n",
    "max_ckpt_to_keep = 3\n",
    "checkpoint_dir = f'./model/non_extorted/x{scale}_checkpoints'\n",
    "checkpoint_name = 'pix-att-net-ckpt'\n",
    "\n",
    "\n",
    "with tf.device(device):\n",
    "    test_dataset = cycle(get_dataset(path.join(CLEAR_IMAGES_DIR, 'train')).batch(4))\n",
    "    \n",
    "    sr_net = PAN(scale, input_lr_shape, checkpoint_dir)\n",
    "    sr_net.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "def resize_batch(X, target_size, inter=cv2.INTER_CUBIC):\n",
    "    return tf.constant([cv2.resize(x, target_size, interpolation=inter).astype(np.uint8) for x in X.numpy().astype(np.uint8)], dtype=tf.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(test_dataset)\n",
    "y = tf.cast(y, tf.uint8)\n",
    "\n",
    "plot_multiple_images([tf.cast(X, tf.uint8), np.ones(X.shape) * 255], figsize=(6, 6), title=f'Source images')\n",
    "\n",
    "print('Max possible psnr', round(float(tf.reduce_mean(tf.image.psnr(y, y, 255))), 4))\n",
    "y_hat = resize_batch(X, HR_IMAGE_SIZE, cv2.INTER_LINEAR)\n",
    "psnr = round(float(tf.reduce_mean(tf.image.psnr(y, y_hat, 255))), 4)\n",
    "plot_multiple_images([y_hat, y], figsize=(6, 6), title=f'Bilinear inter PSNR: {psnr}')\n",
    "# plot_multiple_images([y_hat, y], figsize=(6, 6))\n",
    "# plt.savefig('./x4/bilinear_inter_results.png')\n",
    "\n",
    "\n",
    "y_hat = resize_batch(X, HR_IMAGE_SIZE, cv2.INTER_CUBIC)\n",
    "psnr = round(float(tf.reduce_mean(tf.image.psnr(y, y_hat, 255))), 4)\n",
    "plot_multiple_images([y_hat, y], figsize=(6, 6), title=f'Bicubic inter PSNR: {psnr}')\n",
    "# plot_multiple_images([y_hat, y], figsize=(6, 6))\n",
    "# plt.savefig('./x4/bicubic_inter_results.png')\n",
    "\n",
    "y_hat = sr_net(X, training=False)\n",
    "psnr = round(float(tf.reduce_mean(tf.image.psnr(y, y_hat, 255))), 4)\n",
    "msssim = round(float(tf.reduce_mean(tf.image.ssim_multiscale(y_hat, y, 255))), 4)\n",
    "plot_multiple_images([y_hat, y], figsize=(6, 6), title=f'Model PSNR: {psnr}. MS-SSIM: {msssim}')\n",
    "# plot_multiple_images([y_hat, y], figsize=(6, 6))\n",
    "# plt.savefig('./x4/sr_model_inter_results.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "\n",
    "# metrics_test_model = partial(resize_batch, target_size=HR_IMAGE_SIZE, inter=cv2.INTER_LINEAR)\n",
    "# metrics_test_model = partial(resize_batch, target_size=HR_IMAGE_SIZE, inter=cv2.INTER_CUBIC)\n",
    "metrics_test_model = partial(sr_net, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_batch_psnr = 0.0\n",
    "mean_batch_ssim = 0.0\n",
    "mean_batch_msssim = 0.0\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    batch_size = 50\n",
    "    dataset = get_dataset(path.join(CLEAR_IMAGES_DIR, 'test'))\n",
    "    n_batches = 0\n",
    "    for batch_x, batch_y in dataset.batch(batch_size):\n",
    "        batch_y = tf.cast(batch_y, tf.uint8)\n",
    "        y_hat = metrics_test_model(batch_x)\n",
    "        mean_batch_psnr += tf.reduce_mean(tf.image.psnr(y_hat, batch_y, 255))\n",
    "        mean_batch_ssim += tf.reduce_mean(tf.image.ssim(y_hat, batch_y, 255))\n",
    "        mean_batch_msssim += tf.reduce_mean(tf.image.ssim_multiscale(y_hat, batch_y, 255))\n",
    "        n_batches += 1\n",
    "\n",
    "mean_batch_psnr /= n_batches\n",
    "mean_batch_ssim /= n_batches\n",
    "mean_batch_msssim /= n_batches\n",
    "print('PSNR:', round(float(mean_batch_psnr), 4))\n",
    "print('SSIM:', round(float(mean_batch_ssim), 4))\n",
    "print('MSSSIM:', round(float(mean_batch_msssim), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import load\n",
    "\n",
    "\n",
    "with open('./data/img/clear_words_coordinates.json') as fid:\n",
    "    annot = load(fid)\n",
    "    \n",
    "list(annot.keys())[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_text(img_name):\n",
    "    return ' '.join((w_st['word'] for w_st in annot[img_name])) + '\\f'\n",
    "\n",
    "repr(get_true_text('image0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract as tesseract\n",
    "\n",
    "\n",
    "# specify path to the preinstalled binary file of tesseract\n",
    "tesseract.pytesseract.tesseract_cmd = r'C:\\Users\\Dmytro_Shvetsov\\Desktop\\tesseract\\tesseract.exe'\n",
    "print('Tesseract version: ', tesseract.get_tesseract_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import prepare_example\n",
    "from metrics import relative_distance\n",
    "from glob import glob\n",
    "\n",
    "lr_mean_relative_distance = 0.0\n",
    "sr_mean_relative_distance = 0.0\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    test_img_fps = glob(path.join(CLEAR_IMAGES_DIR, 'test/*'))\n",
    "    for fp in test_img_fps:\n",
    "        lr_im, hr_im, fname = prepare_example(tf.convert_to_tensor(fp, dtype=tf.string), ret_img_name=True)\n",
    "\n",
    "        text_true = get_true_text(fname.numpy().decode())\n",
    "        plt.imshow(lr_im.numpy().astype(np.uint8))\n",
    "        text_pred = tesseract.image_to_string(lr_im.numpy().astype(np.uint8))\n",
    "        rel_dist = relative_distance(text_true, text_pred)\n",
    "        lr_mean_relative_distance += rel_dist\n",
    "        \n",
    "        sr_img = sr_net(tf.expand_dims(lr_im, 0), training=False)[0].numpy().astype(np.uint8)\n",
    "        text_pred = tesseract.image_to_string(sr_img)\n",
    "        rel_dist = relative_distance(text_true, text_pred)\n",
    "        sr_mean_relative_distance += rel_dist\n",
    "\n",
    "lr_mean_relative_distance /= len(test_img_fps)\n",
    "sr_mean_relative_distance /= len(test_img_fps)\n",
    "print('Mean relative distance without sr', float(lr_mean_relative_distance))\n",
    "print('Mean relative distance with sr', float(sr_mean_relative_distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from src.data import prepare_example\n",
    "from metrics import relative_distance\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "test_img_fps = glob(path.join(CLEAR_IMAGES_DIR, 'test/*'))\n",
    "fp = test_img_fps[5]\n",
    "lr_im, hr_im, fname = prepare_example(tf.convert_to_tensor(fp, dtype=tf.string), ret_img_name=True, lr_img_size=(64, 64))\n",
    "sr_img = tf.clip_by_value(sr_net(tf.expand_dims(lr_im, 0), training=False)[0], 0, 255).numpy().astype(np.uint8)\n",
    "plt.imshow(lr_im.numpy().astype(np.uint8))\n",
    "plt.figure()\n",
    "plt.imshow(sr_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_tf(fp, target_size):\n",
    "    image_string = tf.io.read_file(fp)\n",
    "    image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n",
    "    image = tf.cast(image_decoded, tf.float32) \n",
    "    return tf.image.resize(image_decoded, target_size, method=tf.image.ResizeMethod.BICUBIC)\n",
    "\n",
    "def prepare_example_tf(hr_image_fp, ret_img_name=False, lr_img_size=(128, 128), hr_img_size=(256, 256)):\n",
    "    example = read_image_tf(hr_image_fp, LR_IMAGE_SIZE), read_image_tf(hr_image_fp, HR_IMAGE_SIZE)\n",
    "    if ret_img_name:\n",
    "        img_name = path.split(str(hr_image_fp))[1].split('.')[0]\n",
    "        return example + (tf.constant(img_name),)\n",
    "    else:    \n",
    "        return example\n",
    "\n",
    "\n",
    "fp = test_img_fps[5]\n",
    "lr_im, hr_im, fname = prepare_example_tf(tf.convert_to_tensor(fp, dtype=tf.string), ret_img_name=True)\n",
    "sr_img = sr_net(lr_im[None], training=False)[0]\n",
    "plt.imshow(lr_im.numpy().astype(np.uint8))\n",
    "plt.figure()\n",
    "plt.imshow(sr_img)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
